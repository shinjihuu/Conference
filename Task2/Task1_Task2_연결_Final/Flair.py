# -*- coding: utf-8 -*-
"""[D&A]task1 최종.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19uAccA6iTgDGgwYFH8EvLvon234lTKq4

## Task1 : 키워드 추출
"""

!pip install flair konlpy

"""- 열정
- 팀워크
- 성취지향
- 의사소통
- 분석적사고
- 자원 계획, 관리
- 대인관계/도전정신
- 전문성
- 주인의식
- 문제해결
- 치밀성
- 주도성
"""

from konlpy.tag import Okt
from flair.embeddings import TransformerDocumentEmbeddings
from flair.data import Sentence
import torch

class KeywordExtractor:
    def __init__(self):
        # Okt 형태소 분석기 로드
        self.okt = Okt()
        # 불용어 리스트 정의
        self.stop_words = [
        '이', '그', '저', '그리고', '하지만', '그래서', '또는', '즉', '때문에', '그러나', '그러므로',
        '게다가', '및', '의', '가', '을', '를', '에', '과', '도', '에서', '하다', '이다',
        '않다', '없다', '않고', '있는', '같이', '같은', '한', '안', '중', '더', '너무', '잘', '다',
        '보다', '합니다', '하세요', '합니다', '그런', '위해', '어떻게', '무엇', '나', '우리', '저희',
        '할', '하여', '하면서', '해야', '하고', '되다', '된다', '되는', '된', '될', '하게', '한테',
        '그렇다', '있습니다', '있어', '있다', '였습니다', '이었다', '이러한', '또', '위', '아래',
        '여기', '저기', '거기', '처럼', '이외', '뿐', '각', '모든', '모두', '통해', '뒤', '앞',
        '같다', '라는', '하는', '이런', '이번', '전', '후', '및', '안', '밖', '의해', '만', '까지',
        '무슨', '좀', '좀더', '할지', '아닌'
        ]
        # Flair Transformer 임베딩 모델 로드 (BERT 모델 사용)
        self.embedding_model = TransformerDocumentEmbeddings('bert-base-multilingual-cased')

    def preprocess_text(self, text):
        nouns = self.okt.nouns(text)  # 명사 추출
        filtered_nouns = [word for word in nouns if word not in self.stop_words]  # 불용어 제거
        return ' '.join(filtered_nouns)

    def embed_text(self, text):
        # 문장을 Flair의 Sentence 객체로 변환 후 임베딩
        sentence = Sentence(text)
        self.embedding_model.embed(sentence)
        return sentence.embedding

    def compute_similarity(self, competency_user, keywords):
        # 핵심 역량 문장을 Flair Sentence로 변환하고 임베딩
        keyword_embedding = self.embed_text(competency_user)

        related_keywords = []
        for kw, score in keywords:
            # 추출된 키워드를 Flair Sentence로 변환하고 임베딩
            kw_embedding = self.embed_text(kw)
            # 유사도 계산 (코사인 유사도)
            similarity = torch.nn.functional.cosine_similarity(keyword_embedding, kw_embedding, dim=0)
            if similarity > 0.5:  # 유사도가 0.5 이상인 키워드만 선택
                related_keywords.append((kw, similarity.item()))

        # 유사도 기준으로 정렬
        related_keywords = sorted(related_keywords, key=lambda x: x[1], reverse=True)
        return related_keywords[:5]  # 상위 5개 추출


    '''반환 부분 수정'''
    def extract_keywords(self, document):
        # 키워드 후보를 임의로 생성 (여기선 예시로 문서의 주요 단어)
        processed_text = self.preprocess_text(document)

        '''수정 전'''
        # words = list(set(processed_text.split()))
        # 단어별 유사도 값과 함께 반환 (0.0으로 초기화된 점수)
        # return [(word, 0.0) for word in words]

        '''수정 후'''
        keywords = [(word, 0.0) for word in set(processed_text.split())]
        return keywords
    

    '''최종 반환 코드 추가 (기존 run 함수 - 4. 유사도 계산 및 상위 5개 키워드 출력에서 빼옴)'''
    def final_top5_keywords(self, competency_user, keywords):
        top_related_keywords = self.compute_similarity(competency_user, keywords)
        return top_related_keywords






'''아래 내용은 mian에서 돌리도록 수정'''
    def run(self):
        # 1. 자기소개서 핵심 역량 입력
        # 전 keyword_to_compare, 후 competency_user
        competency_user = input("자기소개서에 드러내고 싶었던 역량을 작성해주세요 : ")

        # 2. 자기소개서 내용 입력
        document = input("자기소개서 내용을 입력해주세요: ")

        # 3. 키워드 추출 (임의의 단어로 추출한 키워드 리스트)
        keywords = self.extract_keywords(document)

        # 4. 유사도 계산 및 상위 5개 키워드 출력
        top_related_keywords = self.compute_similarity(competency_user, keywords)

        print(f"\n'{competency_user}'과 연관된 상위 5개의 키워드:")
        for kw, similarity in top_related_keywords:
            print(f"{kw}: 유사도 {similarity:.4f}")
        return competency_user, top_related_keywords
    
# 클래스 실행 예시
if __name__ == "__main__":
    extractor = KeywordExtractor()
    extractor.run()
