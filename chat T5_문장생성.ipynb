{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4104e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국의 수도는 서울입니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 토크나이저와 모델 로드 및 GPU에 이동\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model.to(device)\n",
    "\n",
    "# 입력 데이터 생성 및 GPU에 이동\n",
    "prompt_tpl = \"사용자가 한 말을 읽고 그에 질문에 답하거나 명령에 응답하는 비서입니다.\\n\\n사용자:\\n{text}\\n\\n비서:\\n\"\n",
    "prompt = prompt_tpl.format(text=\"한국의 수도는 어디인가요?\")\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "\n",
    "# 모델로 추론 수행\n",
    "logits = model.generate(\n",
    "    input_ids,\n",
    "    max_length=1024,\n",
    "    temperature=0.5,\n",
    "    no_repeat_ngram_size=6,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "text = tokenizer.batch_decode(logits, skip_special_tokens=True)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d86c45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"저는 에너지 분야의 적자를 해소하고, 시민들에게 경제적이고 안전한 가스를 공급하고자 KOGAS에 지원하게 되었습니다. 저의 분석적 사고, 최적화, 균형, 문제 해결, 효율성 역량은 ~입니다\"라는 비유 문장은 주어진 키워드를 바탕으로 자신의 역량을 소개하는 과정을 통해 작성됩니다.\n",
      "\n",
      "우선 저의 분석적사고 역량은 에너지 분야의, 즉 '에너지 분야의 흑자 해소'와 관련된 문제를 해결하는 능력을 의미합니다. 이는 에너지 분야의의 흑자를 해소하고,, 시민들에게, 에너지 분야의(KOGAS)의 흑자를 해결하는 데 필요한 역량을 의미합니다.\n",
      "\n",
      "또한, 에너지 분야에서 'Rock-Drill' 기법을 활용하여 재고와 생산 프로세스 최적화 기법을 사용하여 실제 산업 사례를 반영한 과제를 성공적으로 수행했습니다. 이는 에너지의 효율성을 향상시키고, 에너지 산업의 발전을 촉진하는 데 기여합니다.\n",
      "\n",
      "또한 'Rock Drill' 방법을 활용하여 에너지 산업 사례를, 'Rock' 기법을 적용하여 실제 산업의 사례를 반영하여 과제를 수행했습니다. 이 과정은 에너지 산업의, 즉 \"Rock-Dryll\" 기법을 활용한 재고와 생산의 최적화 기법으로, 에너지 산업 분야의 적자 해소와 에너지 산업의의 발전을 위한 최적의 방법을 도출하는 과정입니다.\n",
      "\n",
      "이처럼 저의 분석적, 최적화,\n",
      "균형, 문제 해소, 효율성 능력은 ~입니다. 이는 에너지산업의 발전과 소비자들의 편익을 고려하여 에너지 산업의...\n",
      "\n",
      "또한,, 에너지 수요 관리 분야에서는 에너지 산업의발전과 소비자 편익을 고려한 최적의 방안을 도출하는 능력을 가지고 있습니다. 이는 에너지, 에너지 산업, 소비자 편익 등을 고려하여 최소한의 비용 문제를 해결할 수 있는 깊이 있는 과제를 수행합니다. 이를 통해, 에너지 산업에서의 적자 해소와, 소비자들의이익 증대를 위해 에너지 산업의개발과 비용 절감을 실현할 수 있습니다.\n",
      "\n",
      "따라서, 저의 분석적이고 최적화된 사고와 최적화된 균형, 문제해결 능력은 ~이며, 에너지 분야에서의 적자 해소 및 시민들의 편익 제고에 도움을 주고자 지원합니다.\n"
     ]
    }
   ],
   "source": [
    "## 임의로 작성한 프롬프트\n",
    "import torch\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 토크나이저와 모델 로드 및 GPU에 이동\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model.to(device)\n",
    "\n",
    "# 입력 데이터 생성 및 GPU에 이동\n",
    "prompt_tpl = \"자기소개서와 주어진 키워드를 바탕으로 나를 소개하는 은유문장을 생성해주는 프로그램이야.비유 문장은 반드시 '저의 {keyword} 역량은 ~입니다.' 형식으로 작성되어야 하며, 간결하고 명확해야 합니다.\\n\\n자기소개서:\\n{text_1}\\n\\n키워드:\\n{keyword}\\n\\n프로그램:\\n\"\n",
    "prompt = prompt_tpl.format(text_1=\"에너지 분야의 적자를 해소하고, 시민들에게 경제적이고 안전한 가스를 공급해드리고 싶어 KOGAS에 지원하게 되었습니다. 물류관리 수업에서 재고와 생산 프로세스 최적화 기법인 'Rock-Drill' 방식을 적용, 실제 산업 사례를 반영한 과제를 성공적으로 수행했습니다. 공급사슬 총괄 계획에서 인적자원, 초과시간, 재고비용, 생산 수를 조절하며 최적의 해를 찾는 연습을 수행했습니다. 요소 간의 균형을 이해하며 분석적 사고 능력을 발전시켰습니다. 나아가 마케팅 캠페인, 규모의 경제, 시간 관리와 같이 불확실한 요소를 고려해 최소 비용 문제를 해결하는 깊이 있는 과제를 완수했습니다. 이렇게 쌓은 제 능력을 가스 수요관리 분야에 적용시킬 수 있습니다. 지역별, 시기별 가스 수요를 조사하여 요소들을 고려하고, 최적의 해를 도출하는 방향으로 활용할 수 있습니다. 이러한 역량을 통해, KOGAS의 적자 해소 및 시민들의 효용 제고에 도움을 주고자 지원했습니다.\",\n",
    "                            keyword=\"분석적 사고, 최적화, 균형, 문제 해결, 효율성\")\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "\n",
    "# 모델로 추론 수행\n",
    "logits = model.generate(\n",
    "    input_ids,\n",
    "    max_length=1024,\n",
    "    temperature=0.5,\n",
    "    no_repeat_ngram_size=6,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "text = tokenizer.batch_decode(logits, skip_special_tokens=True)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94e785f",
   "metadata": {},
   "source": [
    "### 결과\n",
    "- 원하는 내용과는 아예 다른 내용이 출력된다.\n",
    "- 다른 프롬프트를 사용해 확인해봐야하고 파인튜닝 필요가 있어보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10934a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"에너지 분야의 적자를 해소하고, 시민들에게 경제적이고 안전한 가스를 공급하고 싶어 KOGAS에 지원했습니다.\"\n"
     ]
    }
   ],
   "source": [
    "## 통일한 프롬프트\n",
    "import torch\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 토크나이저와 모델 로드 및 GPU에 이동\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model.to(device)\n",
    "\n",
    "# 입력 데이터 생성 및 GPU에 이동\n",
    "prompt_template = \"\"\"\n",
    "주어진 키워드 '{keyword}'와 자기소개서 \"{text}\"를 바탕으로, 해당 키워드가 의미하는 역량을 나타내는 비유 문장 5개를 작성하고, 각 문장에 대한 설명을 추가하세요.  \n",
    "비유 문장은 반드시 '저의 {keyword} 역량은 ~입니다.' 형식으로 작성되어야 하며, 간결하고 명확해야 합니다.\n",
    "설명 문장에서는 선택된 비유 대상(예: 나침반)이 왜 그 키워드와 관련이 있는지, 그리고 그 대상이 키워드의 의미와 어떻게 연결되는지를 구체적으로 설명해주세요.\n",
    "각 키워드에 대해 비유 문장과 각 문장에 대한 설명을 5개씩 작성해주세요.\n",
    "\"\"\"\n",
    "prompt = prompt_template.format(\n",
    "    text=\"에너지 분야의 적자를 해소하고, 시민들에게 경제적이고 안전한 가스를 공급해드리고 싶어 KOGAS에 지원하게 되었습니다. 물류관리 수업에서 재고와 생산 프로세스 최적화 기법인 'Rock-Drill' 방식을 적용, 실제 산업 사례를 반영한 과제를 성공적으로 수행했습니다. 공급사슬 총괄 계획에서 인적자원, 초과시간, 재고비용, 생산 수를 조절하며 최적의 해를 찾는 연습을 수행했습니다. 요소 간의 균형을 이해하며 분석적 사고 능력을 발전시켰습니다. 나아가 마케팅 캠페인, 규모의 경제, 시간 관리와 같이 불확실한 요소를 고려해 최소 비용 문제를 해결하는 깊이 있는 과제를 완수했습니다. 이렇게 쌓은 제 능력을 가스 수요관리 분야에 적용시킬 수 있습니다. 지역별, 시기별 가스 수요를 조사하여 요소들을 고려하고, 최적의 해를 도출하는 방향으로 활용할 수 있습니다. 이러한 역량을 통해, KOGAS의 적자 해소 및 시민들의 효용 제고에 도움을 주고자 지원했습니다.\",\n",
    "    keyword=\"분석적 사고, 최적화, 균형, 문제 해결, 효율성\"\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "\n",
    "# 모델로 추론 수행\n",
    "logits = model.generate(\n",
    "    input_ids,\n",
    "    max_length=1024,\n",
    "    temperature=0.5,\n",
    "    no_repeat_ngram_size=6,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "text = tokenizer.batch_decode(logits, skip_special_tokens=True)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98783ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"에너지 분야의 적자를 해소하고, 시민들에게 경제적이고 안전한 가스를 공급해주고 싶어 KOGAS에 지원하게 되었습니다. 이 지원을 통해 에너지 분야의 문제를 해결하고, 에너지 분야의, 에너지 분야 문제를 해결하는 데 큰 도움을 줄 수 있습니다.\"\n",
      "\n",
      "\"에너지 분야의,\n",
      "에너지 분야의 위기를 해결하고,\n",
      "시민들에게 경제적인 이익을 제공하고,\n",
      "에너지 분야 문제 해결에 큰 도움을줍니다.\"\n",
      "\n",
      "\"저의 분석적 사고, 최적화, 균형, 문제 해결, 효율성 역량은 (비유)입니다\"\n",
      "\n",
      "\"에너지, 에너지 분야에서 위기를 해결하는 것은 에너지 분야의.\n",
      "에너지 분야의. 위기를 해결하기 위한 최선의 방법은 무엇인가요?\"\n",
      "\n",
      "\"저는 에너지 분야의에 지원하게 된 이유에 대해 설명하겠습니다. 이 지원은 에너지 분야에서, 에너지 분야에 대한 위기 해결 역량을 향상시키고, 에너지 분야에서의 에너지 문제를 해결하기 위해 지원합니다.\"\n",
      "\n",
      "\"저를 에너지 분야의의 위기에서 해결하기 위해, KOGA스에 지원하게 되어 기쁩니다. 이 지원으로 에너지 분야의에서 위기를 극복하고, 에너지 산업의 위기를 극복할 수 있기를 바랍니다.\"\n",
      "\n",
      "\"제가 에너지 분야의에서의 위기를 해결하고자, KOGOS에 지원하게된 이유는 에너지 분야에서의, 에너지 분야만의 위기 해결 능력을 향상시키기 위함입니다.\"\n",
      "\n",
      "\"이 지원을 통한 저의 분석적 생각과 최적화, 그리고 문제 해결 능력을, 에너지 분야를 위기에서 해결하는 데에 도움을 줄수 있기를 기대합니다.\"\n",
      "\n",
      "이 생각을 바탕으로, 저는 에너지 산업의. 위기를. 해결하기 위해. 에너지 분야의? 위기를 극복하기 위해. 문제 해결을 위해 노력합니다. 이 지원의 목적은 에너지 산업의? 위기를. 극복하기 위해 노력합니다, 이 지원을\n"
     ]
    }
   ],
   "source": [
    "## 통일한 프롬프트\n",
    "import torch\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 토크나이저와 모델 로드 및 GPU에 이동\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model.to(device)\n",
    "\n",
    "# 입력 데이터 생성 및 GPU에 이동\n",
    "prompt_template = \"\"\"\n",
    "주어진 키워드 '{keyword}'와 자기소개서 \"{text}\"를 바탕으로, 해당 키워드가 의미하는 역량을 나타내는 비유 문장 5개를 작성하고, 각 문장에 대한 설명을 추가하세요.  \n",
    "비유 문장은 반드시 '저의 {keyword} 역량은 (비유)입니다.' 형식으로 작성되어야 하며, 간결하고 명확해야 합니다.\n",
    "설명 문장에서는 선택된 비유 대상(예: 나침반)이 왜 그 키워드와 관련이 있는지, 그리고 그 대상이 키워드의 의미와 어떻게 연결되는지를 구체적으로 설명해주세요.\n",
    "각 키워드에 대해 비유 문장과 각 문장에 대한 설명을 5개씩 작성해주세요.\n",
    "\"\"\"\n",
    "prompt = prompt_template.format(\n",
    "    text=\"에너지 분야의 적자를 해소하고, 시민들에게 경제적이고 안전한 가스를 공급해드리고 싶어 KOGAS에 지원하게 되었습니다. 물류관리 수업에서 재고와 생산 프로세스 최적화 기법인 'Rock-Drill' 방식을 적용, 실제 산업 사례를 반영한 과제를 성공적으로 수행했습니다. 공급사슬 총괄 계획에서 인적자원, 초과시간, 재고비용, 생산 수를 조절하며 최적의 해를 찾는 연습을 수행했습니다. 요소 간의 균형을 이해하며 분석적 사고 능력을 발전시켰습니다. 나아가 마케팅 캠페인, 규모의 경제, 시간 관리와 같이 불확실한 요소를 고려해 최소 비용 문제를 해결하는 깊이 있는 과제를 완수했습니다. 이렇게 쌓은 제 능력을 가스 수요관리 분야에 적용시킬 수 있습니다. 지역별, 시기별 가스 수요를 조사하여 요소들을 고려하고, 최적의 해를 도출하는 방향으로 활용할 수 있습니다. 이러한 역량을 통해, KOGAS의 적자 해소 및 시민들의 효용 제고에 도움을 주고자 지원했습니다.\",\n",
    "    keyword=\"분석적 사고, 최적화, 균형, 문제 해결, 효율성\"\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "\n",
    "# 모델로 추론 수행\n",
    "logits = model.generate(\n",
    "    input_ids,\n",
    "    max_length=1024,\n",
    "    temperature=0.5,\n",
    "    no_repeat_ngram_size=6,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "text = tokenizer.batch_decode(logits, skip_special_tokens=True)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc600988",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "- 관련 내용의 문장이 생성되지만 비유문장 생성이 되지 않음\n",
    "- 프롬프팅 내용의 문장이 많은 영향을 끼치는 것처럼 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eef48a",
   "metadata": {},
   "source": [
    "#### 프롬프팅 + 퓨샷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7429279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 저의 기획 역량은 GPS와 같습니다. 이는 제가 제시한 아이디어와 주제를 고려하여 기획을 진행하는 것을 의미합니다. GPS는 주제의 구체성과 정확성을 평가하고, 주제의 타당성을 평가하는 지표입니다. GPS를 통해 주제를 고려하고 해결책을 도출하는 과정을 보여줍니다.\n",
      "\n",
      "2. 저의 기획력은 교통 신호등입니다. 교통 신호등은 건물을 짓기 위한 구체적인 설계도를 제공하며, 제가 발표팀을 선별하여 문제를 해결한 과정을 보여주며, 주제의 복잡성을 고려하여 문제를 도출하는 과정과 결과를 보여줍니다.\n",
      "   - 교통 신호등은, 제가 제시하는 아이디어와 주제에 따라 문제를 해결할 수 있는 방법을 제시합니다. 교통 신호등을 통해 저는 특정 지역을 선택하여 학술제를 진행할 수 있도록 계획을 수립합니다.\n",
      "    - 제가 제시된 아이디어와 주제가 어떤 문제를 해결하기에 적합한지를 판단하고, 이를 기반으로 학술제를 실시할 수 있습니다.\n",
      "\n",
      "3. 저의 기획적 역량은 물류 디자인입니다. 물류 디자인은 특정 분야의 자원을 효율적으로 사용하여 프로젝트를 진행하는 것입니다. 물류 설계는 특정 분야의자원을 효율적이고 효율적으로 활용하는 것을 목표로 합니다. 물류 디자인을 통해 저를 대상으로 한 프로젝트는 물류 시스템을 개선하고, 물류 시스템을개선하는 것을 목적으로 합니다.\n",
      "  - 물류 디자인은, 제가제시한 아이디어와, 주제를 기반으로 프로젝트를 진행할 것을 제안합니다.\n",
      "  \n",
      " - 물류 설계는, 제가 제안한 아이디어와 목표를 고려하여 프로젝트를 추진하는 과정을 나타내는 지표입니다. 물류 시스템은 프로젝트 중에서 특정 분야의, 특히 에너지 분야의 자원 활용에 대한 고려를 반영하여 프로젝트를 수행합니다.\n",
      "  (예: 물류 디자인을, 물류 디자인을)\n",
      "   -\n",
      "   -- 물류 디자인을... 물류 디자인과 물류 시스템을... \n",
      "   -_\n",
      "   -사회적 문제를 해결하고, 사회적 문제를, 사회적 이슈를 해결하고,\n",
      "   -(사회적 이슈를, 사회적으로 이슈를)\n",
      "      --\n",
      "    제가 제시하고 싶은 아이디어와 주제의 타당성과 정확성을, 사회적 의제와 이슈를 해결하는 데 도움을 줄 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "## 통일한 프롬프트\n",
    "import torch\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 토크나이저와 모델 로드 및 GPU에 이동\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model.to(device)\n",
    "\n",
    "# 입력 데이터 생성 및 GPU에 이동\n",
    "prompt_template = \"\"\"\n",
    "주어진 키워드 '{keyword}'와 자기소개서 \"{text}\"를 바탕으로, 해당 키워드가 의미하는 역량을 나타내는 비유 문장 5개를 작성하고, 각 문장에 대한 설명을 추가하세요.  \n",
    "비유 문장은 반드시 '저의 {keyword} 역량은 (비유문장)입니다.' 형식으로 작성되어야 하며, 간결하고 명확해야 합니다.\n",
    "설명 문장에서는 선택된 비유 대상이 왜 그 키워드와 관련이 있는지, 그리고 그 대상이 키워드의 의미와 어떻게 연결되는지를 구체적으로 설명해주세요.\n",
    "각 키워드에 대해 비유 문장과 각 문장에 대한 설명을 5개씩 작성해주세요.\n",
    "\n",
    "그 예시는 다음과 같습니다.\n",
    "자기소개서: '대학교 3학년 때, 학생회 활동으로 교내 학술 대회를 주최한 적이 있습니다. 특별한 학술제 기획과 참여 인원을 모집하는 것에 집중하여 학술제 광고지를 제작하여, SNS와 학과 게시판에 홍보를 진행하였습니다. 이에 너무 많은 팀이 몰렸고, 학술제 예상 소요 시간이 길다는 차질이 발생하였습니다. 예정일에 학술제를 진행할 수 있도록 대략적 계획을 구체화하여 학술제 기획을 진행하였습니다. 발표팀을 선별하고자 논문을 살펴보며 순위를 설정하여 높은 수준의 논문을 추려낼 수 있도록 하였습니다. 선정팀 발표와 동시에 이벤트를 공지하여 미참가자들에게도 학술제 참여를 유도할 수 있도록 하였습니다. 이 활동으로 프로젝트를 기획하는 역량과 문제 해결 능력을 향상시켰다고 할 수 있습니다.'\n",
    "\n",
    "키워드: 주최, 기획, 진행, 선별, 유도\n",
    "\n",
    "1. 저의 주최 역량은 GPS와 같습니다.\n",
    "   - GPS는 목적지로 가는 최적의 경로를 제시하며, 돌발 상황에서도 경로를 재조정합니다. 학술제를 주최하면서 예상보다 많은 참가팀이 몰리는 문제를 빠르게 인식하고 발표팀을 선별하여 문제를 해결한 과정은 저의 주최 역량이 정확하게 문제를 진단하고 해결 방법을 찾는 데 발휘되었음을 보여줍니다.\n",
    "\n",
    "2. 저의 기획 역량은 건축 도면입니다.\n",
    "   - 건축 도면이 건물을 짓기 위한 구체적인 설계도를 제공하듯, 저의 기획 역량은 복잡한 과업을 구체적이고 체계적으로 설계하는 역할을 합니다. 학술제 기획을 하면서 발표팀 선별, 논문 검토 등을 통해 행사를 원활하게 진행할 수 있도록 계획을 세운 과정이 이를 잘 보여줍니다.\n",
    "\n",
    "3. 저의 진행 역량은 교통 신호등입니다.\n",
    "   - 교통 신호등이 흐름을 관리하듯, 저는 학술제의 진행을 효율적으로 관리했습니다. 너무 많은 팀이 몰렸을 때 발표팀을 선별하여 진행 시간을 조정한 것은 적절한 판단을 통해 혼란을 방지하고 흐름을 제어한 예시입니다.\n",
    "\n",
    "4. 저의 선별 역량은 외과의사의 수술 과정과 같습니다.\n",
    "   - 외과의사는 수술 중 발생하는 다양한 상황에 맞춰 즉각적으로 판단하고 대응합니다. 저는 예상보다 많은 팀이 참가해 학술제 시간이 길어질 상황에서, 발표팀을 선별하고 논문을 평가하여 학술제를 원활하게 진행할 수 있도록 조정했습니다.\n",
    "\n",
    "5. 저의 유도 역량은 바람을 타고 흐르는 연입니다.\n",
    "   - 연은 바람의 방향에 맞춰 부드럽게 움직이며 유연하게 조종됩니다. 학술제에서 참가자 외에도 비참가자들이 참여할 수 있도록 이벤트를 기획해 학술제를 성공적으로 유도해 낸 경험은, 저의 유도 역량이 상황에 맞춰 유연하게 대처할 수 있음을 보여줍니다.\n",
    "\n",
    " 다만 이는 형식을 보여주는 예시일 뿐이다. 위에서 먼저 언급한 키워드와 자기소개서에 맞게 문장을 생성해주세요.\n",
    "\"\"\"\n",
    "prompt = prompt_template.format(\n",
    "    text=\"에너지 분야의 적자를 해소하고, 시민들에게 경제적이고 안전한 가스를 공급해드리고 싶어 KOGAS에 지원하게 되었습니다. 물류관리 수업에서 재고와 생산 프로세스 최적화 기법인 'Rock-Drill' 방식을 적용, 실제 산업 사례를 반영한 과제를 성공적으로 수행했습니다. 공급사슬 총괄 계획에서 인적자원, 초과시간, 재고비용, 생산 수를 조절하며 최적의 해를 찾는 연습을 수행했습니다. 요소 간의 균형을 이해하며 분석적 사고 능력을 발전시켰습니다. 나아가 마케팅 캠페인, 규모의 경제, 시간 관리와 같이 불확실한 요소를 고려해 최소 비용 문제를 해결하는 깊이 있는 과제를 완수했습니다. 이렇게 쌓은 제 능력을 가스 수요관리 분야에 적용시킬 수 있습니다. 지역별, 시기별 가스 수요를 조사하여 요소들을 고려하고, 최적의 해를 도출하는 방향으로 활용할 수 있습니다. 이러한 역량을 통해, KOGAS의 적자 해소 및 시민들의 효용 제고에 도움을 주고자 지원했습니다.\",\n",
    "    keyword=\"분석적 사고, 최적화, 균형, 문제 해결, 효율성\"\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "\n",
    "# 모델로 추론 수행\n",
    "logits = model.generate(\n",
    "    input_ids,\n",
    "    max_length=1024,\n",
    "    temperature=0.5,\n",
    "    no_repeat_ngram_size=6,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "text = tokenizer.batch_decode(logits, skip_special_tokens=True)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ad32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 왜... 퓨샷러닝 예시로 문장 생성을 하는거지...???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2be4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 저는 에너지 분야의 적자를 해소하고, 시민들에게 경제적이고 안전한 가스를 공급해드리고 싶습니다. \n",
      "2. 저는 마케팅 캠페인과 규모의 경제, 시간 관리와 같은 불확실한 요소를 고려해 최소 비용 문제를 해결하는 깊이 있는 과제를 완수했습니다. \n",
      "3. 저는 교통 신호등을 활용하여 교통 사고를 줄이고자 합니다. \n",
      "4. 저는 사회적 책임을 다하고 지역 사회에서 에너지 분야의, 특히 에너지 산업에 기여하고자 합니다. \n",
      "5. 저는 기획 역량과 연관된 키워드를 설명하고 그 키워드의 의미와 연결된 예시를 제시합니다. \n",
      "\n",
      "예시 문장은 \"저의 기획 역량은 GPS와 같습니다.\" 이며, \"저의 기획력은 사회적 책임과 관련된 키워드입니다.\" 입니다. 이 문장은 \"에너지 분야의 흑자를 해소하고,\" 이며, 이는 에너지 분야의의 적자를 해결하고, 시민들의 이익을 증진시키는 것을 의미합니다. \n",
      "\n",
      "예를 들어, \"제가 에너지 분야의에 지원하게 되어 영광입니다.\" 라는 예시 문장은 에너지 분야의에서 적자를 해소하기 위해 노력하고 있다는 것을 의미하며, \"저는 에너지 산업의 적자를 극복하고, 시민들로부터 경제적이고 안정한 가스를 제공해드리고 싶어요.\" 입니다.\n"
     ]
    }
   ],
   "source": [
    "## 통일한 프롬프트\n",
    "import torch\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 토크나이저와 모델 로드 및 GPU에 이동\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model.to(device)\n",
    "\n",
    "# 입력 데이터 생성 및 GPU에 이동\n",
    "prompt_template = \"\"\"\n",
    "주어진 키워드 '{keyword}'와 자기소개서 \"{text}\"를 바탕으로, 해당 키워드가 의미하는 역량을 나타내는 비유 문장 5개를 작성하고, 각 문장에 대한 설명을 추가하세요.  \n",
    "비유 문장은 반드시 '저의 {keyword} 역량은 (비유문장)입니다.' 형식으로 작성되어야 하며, 간결하고 명확해야 합니다.\n",
    "설명 문장에서는 선택된 비유 대상이 왜 그 키워드와 관련이 있는지, 그리고 그 대상이 키워드의 의미와 어떻게 연결되는지를 구체적으로 설명해주세요.\n",
    "각 키워드에 대해 비유 문장과 각 문장에 대한 설명을 5개씩 작성해주세요.\n",
    "\n",
    "그 형식을 보여주기 위한 예시는 다음과 같습니다.(이는 문장생성과 관련된 내용은 아닙니다.)\n",
    "1. 저의 주최 역량은 GPS와 같습니다.\n",
    "2. 저의 기획 역량은 건축 도면입니다.\n",
    "3. 저의 진행 역량은 교통 신호등입니다.\n",
    "\n",
    "먼저 언급한 키워드와 자기소개서에 맞게 예시 형식으로 비유 문장을 생성해주세요.\n",
    "\"\"\"\n",
    "prompt = prompt_template.format(\n",
    "    text=\"에너지 분야의 적자를 해소하고, 시민들에게 경제적이고 안전한 가스를 공급해드리고 싶어 KOGAS에 지원하게 되었습니다. 물류관리 수업에서 재고와 생산 프로세스 최적화 기법인 'Rock-Drill' 방식을 적용, 실제 산업 사례를 반영한 과제를 성공적으로 수행했습니다. 공급사슬 총괄 계획에서 인적자원, 초과시간, 재고비용, 생산 수를 조절하며 최적의 해를 찾는 연습을 수행했습니다. 요소 간의 균형을 이해하며 분석적 사고 능력을 발전시켰습니다. 나아가 마케팅 캠페인, 규모의 경제, 시간 관리와 같이 불확실한 요소를 고려해 최소 비용 문제를 해결하는 깊이 있는 과제를 완수했습니다. 이렇게 쌓은 제 능력을 가스 수요관리 분야에 적용시킬 수 있습니다. 지역별, 시기별 가스 수요를 조사하여 요소들을 고려하고, 최적의 해를 도출하는 방향으로 활용할 수 있습니다. 이러한 역량을 통해, KOGAS의 적자 해소 및 시민들의 효용 제고에 도움을 주고자 지원했습니다.\",\n",
    "    keyword=\"분석적 사고, 최적화, 균형, 문제 해결, 효율성\"\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "\n",
    "# 모델로 추론 수행\n",
    "logits = model.generate(\n",
    "    input_ids,\n",
    "    max_length=1024,\n",
    "    temperature=0.5,\n",
    "    no_repeat_ngram_size=6,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "text = tokenizer.batch_decode(logits, skip_special_tokens=True)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e1e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 아니 왜 비유 문장은 왜 생성이 안되는거니...???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af530ad",
   "metadata": {},
   "source": [
    "### 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "801fb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, PreTrainedTokenizerFast, AutoModelForCausalLM, AutoModelForCausalLM\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    AutoTokenizer,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeca29da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>열정</td>\n",
       "      <td>활활 뜨겁게 타오르는 불꽃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>열정</td>\n",
       "      <td>힘차게 흐르는 격정적인 폭포수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>열정</td>\n",
       "      <td>휘몰아치는 역정적인 폭풍우</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>열정</td>\n",
       "      <td>뜨거운 태양 아래 끓어오르는 모래사장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>열정</td>\n",
       "      <td>끊임없이 전진하는 대형 기관차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>학습능력</td>\n",
       "      <td>번데기가 나비로 성장하는 번데기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>학습능력</td>\n",
       "      <td>새로운 지식이 쌓이는 책</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>학습능력</td>\n",
       "      <td>땅을 적시고 흡수하는 빗물</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>학습능력</td>\n",
       "      <td>천천히 꾸준히 자라 정상까지 만드는 산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>학습능력</td>\n",
       "      <td>올바른 방향으로 길을 찾게해주는 나침판</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                   text\n",
       "0       열정         활활 뜨겁게 타오르는 불꽃\n",
       "1       열정       힘차게 흐르는 격정적인 폭포수\n",
       "2       열정         휘몰아치는 역정적인 폭풍우\n",
       "3       열정   뜨거운 태양 아래 끓어오르는 모래사장\n",
       "4       열정       끊임없이 전진하는 대형 기관차\n",
       "..     ...                    ...\n",
       "576   학습능력      번데기가 나비로 성장하는 번데기\n",
       "577   학습능력          새로운 지식이 쌓이는 책\n",
       "578   학습능력         땅을 적시고 흡수하는 빗물\n",
       "579   학습능력  천천히 꾸준히 자라 정상까지 만드는 산\n",
       "580   학습능력  올바른 방향으로 길을 찾게해주는 나침판\n",
       "\n",
       "[581 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fine_data= pd.read_csv(\"Task2 파인튜닝 데이터 수집.csv\")\n",
    "fine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f358cb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>열정</td>\n",
       "      <td>활활 뜨겁게 타오르는 불꽃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>열정</td>\n",
       "      <td>힘차게 흐르는 격정적인 폭포수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>열정</td>\n",
       "      <td>휘몰아치는 역정적인 폭풍우</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>열정</td>\n",
       "      <td>뜨거운 태양 아래 끓어오르는 모래사장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>열정</td>\n",
       "      <td>끊임없이 전진하는 대형 기관차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>학습능력</td>\n",
       "      <td>번데기가 나비로 성장하는 번데기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>학습능력</td>\n",
       "      <td>새로운 지식이 쌓이는 책</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>학습능력</td>\n",
       "      <td>땅을 적시고 흡수하는 빗물</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>학습능력</td>\n",
       "      <td>천천히 꾸준히 자라 정상까지 만드는 산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>학습능력</td>\n",
       "      <td>올바른 방향으로 길을 찾게해주는 나침판</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                   text\n",
       "0       열정         활활 뜨겁게 타오르는 불꽃\n",
       "1       열정       힘차게 흐르는 격정적인 폭포수\n",
       "2       열정         휘몰아치는 역정적인 폭풍우\n",
       "3       열정   뜨거운 태양 아래 끓어오르는 모래사장\n",
       "4       열정       끊임없이 전진하는 대형 기관차\n",
       "..     ...                    ...\n",
       "576   학습능력      번데기가 나비로 성장하는 번데기\n",
       "577   학습능력          새로운 지식이 쌓이는 책\n",
       "578   학습능력         땅을 적시고 흡수하는 빗물\n",
       "579   학습능력  천천히 꾸준히 자라 정상까지 만드는 산\n",
       "580   학습능력  올바른 방향으로 길을 찾게해주는 나침판\n",
       "\n",
       "[581 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d02f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "model.to(device)\n",
    "\n",
    "def input_keyword(key1, ex1, ex2, *keywords):\n",
    "  keywords = ' '.join(keywords)\n",
    "\n",
    "  prompt = f'''\n",
    "{keywords}이 드러나는 자기 소개 문장을 비유 표현을 사용해서 생성해줘.\n",
    "답변1. 저의 {key1}는 {ex1}입니다. \n",
    "답변2. 저의 {key2}는 {ex2}입니다.\n",
    "답변3. 저의 {keywords}는 '''\n",
    "\n",
    "  with torch.no_grad():\n",
    "    tokens = tokenizer.encode(prompt, return_tensors='pt').to(device=device, non_blocking=True)\n",
    "    gen_tokens = model.generate(tokens, do_sample=True, temperature=0.85, max_length=100)\n",
    "    generated = tokenizer.decode(gen_tokens[0], skip_special_tokens=True)\n",
    "    generated = generated.replace(\"<pad>\", \" \").replace(\"<unk>\", \" \")\n",
    "    \n",
    "  return print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3533746",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, tokenizer, file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        concats = [\n",
    "            label + \"/\" + text for label, text in zip(data[\"target\"], data[\"text\"])\n",
    "        ]\n",
    "        self.item = tokenizer(\n",
    "            concats,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=32,\n",
    "        )[\"input_ids\"]\n",
    "        self.length = len(concats)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.item[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "def GPTDataLoader(tokenizer, file_path, batch_size):\n",
    "    data = GPTDataset(tokenizer, file_path)\n",
    "    return DataLoader(data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cd04987",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = GPTDataLoader(\n",
    "        tokenizer, \"Task2 파인튜닝 데이터 수집.csv\", batch_size=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "153ef3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(input_text, tokenizer, model, num):\n",
    "    sentence_list = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    token_ids = tokenizer(input_text + \"/\", return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    for cnt in tqdm(range(num)):\n",
    "        gen_ids = model.generate(\n",
    "            token_ids,\n",
    "            max_length=50,\n",
    "            repetition_penalty=2.0,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            use_cache=True,\n",
    "            do_sample=True,\n",
    "        )\n",
    "        sentence = tokenizer.decode(gen_ids[0])\n",
    "        sentence = sentence[sentence.index(\"/\") + 1 :]\n",
    "        if \"<pad>\" in sentence:\n",
    "            sentence = sentence[: sentence.index(\"<pad>\")].rstrip()\n",
    "        sentence = sentence.replace(\"<unk>\", \" \").split(\"\\n\")[0]\n",
    "\n",
    "\n",
    "        if cnt % 100 == 0 and cnt != 0:\n",
    "            print(sentence)\n",
    "        sentence_list.append(sentence)\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "219be727",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [31:29<00:00, 16.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열정 : s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "팀워크 : s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성취지향 : s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의사소통 : s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석적사고 : s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대인관계 : s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도전정신 : s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주도성 : s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전문성 : s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주인의식 : 받아가는걸로도와주십시오.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제해결 : s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m열정\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m팀워크\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m성취지향\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m의사소통\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m분석적사고\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m대인관계\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m도전정신\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m주도성\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m전문성\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m주인의식\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m문제해결\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m치밀성\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m협상력\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m융통성\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m위기대처능력\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m책임감\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m성실\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m리더십\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m친절\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m적응력\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m창의성\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m학습능력\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[1;32m---> 30\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Save best model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(input_text, tokenizer, model, num)\u001b[0m\n\u001b[0;32m      6\u001b[0m gen_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m      7\u001b[0m     token_ids,\n\u001b[0;32m      8\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m sentence \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(gen_ids[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 17\u001b[0m sentence \u001b[38;5;241m=\u001b[39m sentence[\u001b[43msentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sentence:\n\u001b[0;32m     19\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m sentence[: sentence\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\u001b[38;5;241m.\u001b[39mrstrip()\n",
      "\u001b[1;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "# model = T5ForConditionalGeneration.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "# model.train()\n",
    "\n",
    "# # Set optimizer, scheduler\n",
    "# optimizer = AdamW(model.parameters(), lr=float(2e-5))\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer, num_warmup_steps=200, num_training_steps=-1\n",
    "# )\n",
    "\n",
    "# min_loss = float('inf')  # 더 높은 초기값 설정\n",
    "# for epoch in range(10):\n",
    "#     print(f\"Training epoch {epoch}\")\n",
    "#     for input_text in tqdm(train_dataloader):\n",
    "#         input_tensor = input_text.to(device)\n",
    "#         outputs = model(input_tensor, labels=input_tensor)\n",
    "#         loss = outputs.loss\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         model.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#     print(f\"epoch {epoch} loss {loss.item():0.2f}\")\n",
    "\n",
    "#     # Generate examples on epoch end\n",
    "#     labels = [\"열정\", \"팀워크\", \"성취지향\", \"의사소통\", \"분석적사고\", \"대인관계\", \"도전정신\", \"주도성\", \"전문성\", \"주인의식\",\n",
    "#              \"문제해결\", \"치밀성\", \"협상력\", \"융통성\", \"위기대처능력\", \"책임감\", \"성실\", \"리더십\", \"친절\", \"적응력\", \"창의성\", \"학습능력\"]\n",
    "#     for label in labels:\n",
    "#         gen = generate(label, tokenizer, model, 1)\n",
    "#         print(f\"{label} : {gen[0]}\")\n",
    "\n",
    "#     # Save best model\n",
    "#     if loss.item() < min_loss:\n",
    "#         min_loss = loss.item()\n",
    "#         model.save_pretrained(\"./best_model\")\n",
    "\n",
    "#     print(\"Training Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = T5TokenizerFast.from_pretrained(\"paust/pko-chat-t5-large\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"./best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_keyword('폭풍우 속에서도 배를 안전하게 몰고 가는 항해사', \n",
    "#               '목표 달성을 위해 각종 문서와 계획을 한데 묶는 사무실의 스테이플러',\n",
    "#               '책임감')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e638ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 146/146 [1:46:31<00:00, 43.78s/it]\n",
      "100%|██████████| 146/146 [21:56<00:00,  9.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 0.3311\n",
      "Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [2:01:27<00:00, 49.91s/it] \n",
      "100%|██████████| 146/146 [21:28<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Average Loss: 0.2717\n",
      "Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [2:06:50<00:00, 52.13s/it] \n",
      "100%|██████████| 146/146 [21:36<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Average Loss: 0.2078\n",
      "Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [2:17:47<00:00, 56.63s/it] \n",
      "100%|██████████| 146/146 [21:21<00:00,  8.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Average Loss: 0.1624\n",
      "Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [2:09:49<00:00, 53.35s/it] \n",
      "100%|██████████| 146/146 [21:35<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Average Loss: 0.1169\n",
      "Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [2:23:27<00:00, 58.96s/it] \n",
      "100%|██████████| 146/146 [21:52<00:00,  8.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Average Loss: 0.0893\n",
      "Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [2:19:18<00:00, 57.25s/it] \n",
      "100%|██████████| 146/146 [21:54<00:00,  9.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Average Loss: 0.0732\n",
      "Saved new best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 75/146 [1:03:15<34:37, 29.26s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration, AdamW\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=100):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        questions = self.data.iloc[idx]['target']\n",
    "        answers = self.data.iloc[idx]['text']\n",
    "\n",
    "        # 토큰 수를 max_length에 맞춰서 자르거나 패딩\n",
    "        inputs = self.tokenizer(questions, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "        labels = self.tokenizer(answers, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs.input_ids[0], \n",
    "            'labels': labels.input_ids[0]\n",
    "        }\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv(\"Task2 파인튜닝 데이터 수집.csv\")\n",
    "\n",
    "# 토크나이저와 모델 로드\n",
    "tokenizer = T5TokenizerFast.from_pretrained('paust/pko-chat-t5-large')\n",
    "model = T5ForConditionalGeneration.from_pretrained('paust/pko-chat-t5-large')\n",
    "model.to(device)\n",
    "\n",
    "# 학습 설정\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "best_loss = float('inf')  # 가장 낮은 손실을 저장하기 위한 변수\n",
    "\n",
    "# DataLoader를 사용하여 데이터 로드\n",
    "batch_size = 4\n",
    "dataset = CustomDataset(df, tokenizer)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 학습 루프에서 데이터 로더 사용\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 모델을 학습 모드로 전환\n",
    "    for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # 모델 학습\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # 역전파 및 가중치 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 에폭이 끝난 후 모델 평가 모드로 전환\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # 최적의 모델 저장\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        model.save_pretrained(\"./best_model\")\n",
    "        print(\"Saved new best model.\")\n",
    "\n",
    "# 학습이 완료된 모델 저장\n",
    "model.save_pretrained(\"./fintuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3de20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
